{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f11a4d-631f-4f53-859e-cf5c8f36ad5f",
   "metadata": {},
   "source": [
    "### Image classification \n",
    "- [venv] anaconda/py310\n",
    "- [date] 2024/12/23\n",
    "- [posi] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c301c912-0a8b-44b5-a30c-7f11518f68b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms.functional import crop\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.models import efficientnet_b2, EfficientNet_B2_Weights\n",
    "\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import Checkpoint\n",
    "from skorch.helper import predefined_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ca5ec-9ad7-4924-841f-22ee14ae4364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 로드 및 Augmentation 설정\n",
    "data_dir = './glasses'  # 데이터셋 루트 경로\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50801b2-a77c-412f-bffe-51cfebe709b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 사용자 정의 Transform: image crop\n",
    "class CustomCrop:\n",
    "    def __init__(self, top, left, height, width):\n",
    "        self.top = top\n",
    "        self.left = left\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return crop(image, self.top, self.left, self.height, self.width)\n",
    "\n",
    "\n",
    "crop_transform = CustomCrop(top=0, left=90, height=1050, width=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b0f0f5-5e60-443e-9c70-3db73a17871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강 설정\n",
    "train_transforms = transforms.Compose([\n",
    "    crop_transform,\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(260, scale=(0.87, 0.87)),\n",
    "    #transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0455b67e-2d92-47ac-83df-d49eff8b18a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_transforms = transforms.Compose([\n",
    "    crop_transform,\n",
    "    transforms.Resize((260, 260)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec56a9b-52fd-48be-aa8a-5efac98f8c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 로드\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=None)\n",
    "dataset, dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56418f1-e1ad-4a12-94a4-065d0e3ab9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation 분리\n",
    "train_idx, valid_idx = train_test_split(\n",
    "    np.arange(len(dataset)),\n",
    "    test_size=0.1,  # 10%를 Validation 데이터로 사용\n",
    "    stratify=dataset.targets,  # 클래스 비율을 유지\n",
    "    shuffle=True,            \n",
    "    random_state=42        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342350ba-0a18-4b39-a32c-d5776d764e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset으로 Train/Valid 데이터 생성\n",
    "train_subset = Subset(dataset, train_idx)\n",
    "valid_subset = Subset(dataset, valid_idx)\n",
    "\n",
    "# Subset에 각각 Transform 적용\n",
    "train_subset.dataset.transform = train_transforms\n",
    "valid_subset.dataset.transform = valid_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087474d4-961b-4465-9c9e-d9b1061cdbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_subset[0]\n",
    "len(train_subset), image.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe2270c-41e9-4fff-b5b4-2ae9a845c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([image for image,_ in train_subset]) \n",
    "y_train = np.array([label for _,label in train_subset])\n",
    "X_valid = np.array([image for image,_ in valid_subset]) \n",
    "y_valid = np.array([label for _,label in valid_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e085f7-b93a-497c-8f05-359b7f418010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch TensorDataset으로 변환\n",
    "train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train, dtype=torch.long))\n",
    "valid_dataset = TensorDataset(torch.tensor(X_valid), torch.tensor(y_valid, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca828167-f88c-4011-b2f8-bebb46247198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. EfficientNet-B2 모델 정의 및 수정\n",
    "class EfficientNetB2Model(nn.Module):\n",
    "    def __init__(self, pretrained=True, num_classes=2):\n",
    "        super().__init__()\n",
    "        #self.base_model = models.efficientnet_b2(pretrained=pretrained)\n",
    "        self.base_model = efficientnet_b2(weights=EfficientNet_B2_Weights.DEFAULT)\n",
    "        self.base_model.classifier[1] = nn.Linear(self.base_model.classifier[1].in_features, num_classes)  # 1408->2\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "        #return F.softmax(o2, dim=1)\n",
    "\n",
    "\n",
    "# 모델 인스턴스화\n",
    "model = EfficientNetB2Model(pretrained=True, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d68a70-5ee2-409b-a0d8-dde5006bd689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Skorch NeuralNetClassifier 정의\n",
    "net = NeuralNetClassifier(\n",
    "    model,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=Adam,\n",
    "    optimizer__lr=1e-3,\n",
    "    max_epochs=1000,\n",
    "    batch_size=batch_size,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_valid__shuffle=False,\n",
    "    train_split=predefined_split(valid_dataset),   \n",
    "    callbacks=[Checkpoint(f_params='best_params.pt')],\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baabf772-e599-46e2-89a5-3a60630098fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.fit(train_dataset, y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6320fcc6-9ee1-48e6-9f6b-ae95bf020b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"best_params_0001.pt\")\n",
    "model.load_state_dict(torch.load(\"best_params_0001.pt\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2f00ee-8645-4113-bfd7-406306e47f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = net.predict(valid_dataset)\n",
    "res, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571ba3e-82e5-4e5a-a25b-255ad921e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 모델 평가\n",
    "accuracy = net.score(X_valid, y=y_valid)\n",
    "print(f'Validation Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893fa58-1ca8-408a-9d03-22983ffc233d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e5df6c-47c8-4c02-bf37-9b3776b39cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = net.predict(train_dataset)\n",
    "res, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369a230-2517-493c-8ab9-976ad79451bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
